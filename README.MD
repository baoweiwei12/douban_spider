
# 豆瓣数据采集项目

本项目旨在通过Python脚本采集豆瓣电影、音乐、图书及相关人物的数据。项目提供了多个采集脚本，支持并发任务和代理配置，适用于大规模数据采集任务。

## 环境要求

- **操作系统**: Windows
- **Python版本**: 3.12
- **包管理器**: pip

## 安装步骤

1. **克隆或下载项目**  
   将项目克隆或下载到本地。

2. **创建并激活虚拟环境**  
   推荐使用虚拟环境来隔离依赖：
   ```bash
   python -m venv venv
   .\venv\Scripts\activate

3. **安装依赖包**
   安装项目所需的依赖包：
   ```bash
   pip install -r requirements.txt
   ```

## 使用说明

### 数据导入

1. **准备数据文件**

   - 将待采集的人物URL数据放入 `./data/person_urls.xlsx`。
   - 将待采集的作品URL数据放入 `./data/subject_urls.csv`。
2. **运行数据导入脚本**

   - 导入人物数据：
     ```bash
     python load_data_person.py
     ```
   - 导入作品数据：
     ```bash
     python load_data_subject.py
     ```

### 数据采集

项目包含7个采集脚本，分别用于不同类型的数据采集任务：

- **`run_1.py`**: 采集人物基本信息
- **`run_2.py`**: 采集人物作品信息（需登录Cookie）
- **`run_3.py`**: 采集人物获奖信息（需登录Cookie）
- **`run_4.py`**: 采集人物合作关系
- **`run_5.py`**: 采集作品基本信息
- **`run_6.py`**: 采集电影演职员表
- **`run_7.py`**: 采集作品获奖信息

运行方式：

```bash
python run_1.py  # 运行第1个采集任务
python run_2.py  # 运行第2个采集任务
# ... 以此类推
```

### 配置说明

每个采集脚本均支持以下配置项：

- **`TASK_NUMS`**: 并发任务数（默认：1）
- **`SECONDS`**: 每轮任务间隔时间（秒）
- **`PROXY_URL`**: 代理服务器地址（可选）
- **`COOKIES_LIST`**: Cookie信息（仅 `run_2.py`和 `run_3.py`需要）
- **`EVERY_TIMES_SLEEP`**: 每次请求间隔时间（部分脚本需要）

## 注意事项

1. **代理IP**建议使用代理IP进行采集，以避免IP被封禁。
2. **登录Cookie**部分数据需要登录后才能获取，请确保提供有效的Cookie信息。
3. **请求频率控制**合理设置并发数和请求间隔，避免对目标网站造成过大压力。
4. **测试建议**
   建议先进行小规模测试，确保脚本运行正常后再进行大规模采集。

## 文件说明

- **`requirements.txt`**: 项目依赖包列表
- **`load_data_*.py`**: 数据导入脚本
- **`run_*.py`**: 采集任务脚本
- **`data/`**: 存放待采集的URL数据

